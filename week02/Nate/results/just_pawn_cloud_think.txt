## Claud based system prompt and prompt_best
##             "max_tokens": 20,
##            "temperature": 0.3,
##            "top_p": 0.1


NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-4.1-mini
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model anthropic/claude-sonnet-4
Response: <think>
Let me analyze this FEN position: 6B1/8/3
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-3.5-turbo-instruct
Response: [Marvin][text : Qh4]
NEXT MODEL GOING TO THE PIPE
Calling model deepseek/deepseek-chat-v3.1
Response: Qd3+
NEXT MODEL GOING TO THE PIPE
Calling model meta-llama/llama-3.3-8b-instruct:free
Response: Qd3
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-5-chat
Response: Qf3#
NEXT MODEL GOING TO THE PIPE
Calling model qwen/qwen3-coder
Response: Qh4#
NEXT MODEL GOING TO THE PIPE
Calling model meituan/longcat-flash-chat
Response: Qd3+
NEXT MODEL GOING TO THE PIPE
Calling model mistralai/mistral-medium-3.1
Response: Qd4
NEXT MODEL GOING TO THE PIPE
Calling model baidu/ernie-4.5-vl-28b-a3b
Response: Khk
NEXT MODEL GOING TO THE PIPE

## and now without the think (seems better)

------------------------
Going to test the models
------------------------
Calling model google/gemini-2.5-flash-lite
Response: Qxh7
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-4.1-mini
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model anthropic/claude-sonnet-4
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-3.5-turbo-instruct
Response: [Marvin][text : Qh4]
NEXT MODEL GOING TO THE PIPE
Calling model deepseek/deepseek-chat-v3.1
Response: Qd3+
NEXT MODEL GOING TO THE PIPE
Calling model meta-llama/llama-3.3-8b-instruct:free
Response: Qd2
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-5-chat
Response: Qf3#
NEXT MODEL GOING TO THE PIPE
Calling model qwen/qwen3-coder
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model meituan/longcat-flash-chat
Response: Qd3+
NEXT MODEL GOING TO THE PIPE
Calling model mistralai/mistral-medium-3.1
Response: Qd4
NEXT MODEL GOING TO THE PIPE
Calling model baidu/ernie-4.5-vl-28b-a3b
Response: Kh4

------------------------
Going to test the models
------------------------
Calling model google/gemini-2.5-flash-lite
Response: Qxh7
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-4.1-mini
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model anthropic/claude-sonnet-4
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-3.5-turbo-instruct
Response: [Marvin][text : Qh4]
NEXT MODEL GOING TO THE PIPE
Calling model deepseek/deepseek-chat-v3.1
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model meta-llama/llama-3.3-8b-instruct:free
Response: Qd2
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-5-chat
Response: Qf3#
NEXT MODEL GOING TO THE PIPE
Calling model qwen/qwen3-coder
Response: Qh4#
NEXT MODEL GOING TO THE PIPE
Calling model meituan/longcat-flash-chat
Response: Qd3+
NEXT MODEL GOING TO THE PIPE
Calling model mistralai/mistral-medium-3.1
Response: Qd4
NEXT MODEL GOING TO THE PIPE
Calling model baidu/ernie-4.5-vl-28b-a3b
Response: Kh4

------------------------
Going to test the models
------------------------
Calling model google/gemini-2.5-flash-lite
Response: Qxh7
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-4.1-mini
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model anthropic/claude-sonnet-4
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-3.5-turbo-instruct
Response: [Marvin][text : Qh4]
NEXT MODEL GOING TO THE PIPE
Calling model deepseek/deepseek-chat-v3.1
Response: Qd3#
NEXT MODEL GOING TO THE PIPE
Calling model meta-llama/llama-3.3-8b-instruct:free
Response: Qd2
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-5-chat
Response: Qf3#
NEXT MODEL GOING TO THE PIPE
Calling model qwen/qwen3-coder
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model meituan/longcat-flash-chat
Response: Qd3+
NEXT MODEL GOING TO THE PIPE
Calling model mistralai/mistral-medium-3.1
Response: Qd5+
NEXT MODEL GOING TO THE PIPE
Calling model baidu/ernie-4.5-vl-28b-a3b
Response: Kh4
NEXT MODEL GOING TO THE PIPE

------------------------
Going to test the models
------------------------
Calling model google/gemini-2.5-flash-lite
Response: Qxh7
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-4.1-mini
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model anthropic/claude-sonnet-4
Response: Qh3#
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-3.5-turbo-instruct
Response: [Marvin][text : Qh4]
NEXT MODEL GOING TO THE PIPE
Calling model deepseek/deepseek-chat-v3.1
Response: Qd3+
NEXT MODEL GOING TO THE PIPE
Calling model meta-llama/llama-3.3-8b-instruct:free
Response: Qd2
NEXT MODEL GOING TO THE PIPE
Calling model openai/gpt-5-chat
Response: Qf3
NEXT MODEL GOING TO THE PIPE
Calling model qwen/qwen3-coder
Response: Qh4#
NEXT MODEL GOING TO THE PIPE
Calling model meituan/longcat-flash-chat
Response: Qd3+
NEXT MODEL GOING TO THE PIPE
Calling model mistralai/mistral-medium-3.1
Response: Qd4
NEXT MODEL GOING TO THE PIPE
Calling model baidu/ernie-4.5-vl-28b-a3b
Response: Kh4
NEXT MODEL GOING TO THE PIPE
