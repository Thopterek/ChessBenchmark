## Benchmarking LLMs through utilization of chess

<img width="1165" height="624" alt="image" src="https://github.com/user-attachments/assets/2297a121-86a7-44e5-8d78-dc3db536e016" />

<img width="1032" height="619" alt="image" src="https://github.com/user-attachments/assets/13689989-5b4e-4a28-ac04-26dd8e248aaa" />

<img width="1187" height="621" alt="image" src="https://github.com/user-attachments/assets/8741746e-af38-4ae7-8d7a-f1bcca3ad568" />

<img width="1158" height="602" alt="image" src="https://github.com/user-attachments/assets/e8badac4-07ec-49ae-8d52-ee5ae6b4c151" />

<img width="1179" height="568" alt="image" src="https://github.com/user-attachments/assets/2f8c98bb-f30d-4320-8700-acd4eb9f0987" />

<img width="1165" height="626" alt="image" src="https://github.com/user-attachments/assets/1bfbc7e8-2a81-4efd-84b8-0578d46defcf" />

<img width="1160" height="590" alt="image" src="https://github.com/user-attachments/assets/6a05a138-d984-46aa-af8d-70cb0c56e09a" />

<img width="1163" height="585" alt="image" src="https://github.com/user-attachments/assets/03cea981-ad9f-4899-bde8-efacfa438669" />

## Some of the results

<img width="1161" height="468" alt="image" src="https://github.com/user-attachments/assets/084d05c8-abac-4999-95e4-0889705e338b" />

<img width="1146" height="562" alt="image" src="https://github.com/user-attachments/assets/0db09870-e7ae-4500-be08-4e82af104343" />

## Related research

[Bridging the Gap between Expert and Language Models: Concept-guided Chess Commentary Generation and Evaluation](https://aclanthology.org/2025.naacl-long.481.pdf)

[Large Language Models as General Pattern Machines](https://arxiv.org/pdf/2307.04721)

[Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models](https://arxiv.org/pdf/2206.04615)

[Validity Challenges in Machine Learning Benchmarks](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2022/EECS-2022-180.pdf)

[GAIA:A BENCHMARK FOR GENERAL AI ASSISTANTS](https://scontent-fra3-1.xx.fbcdn.net/v/t39.2365-6/441903294_1131492964728662_1145973121044474930_n.pdf?_nc_cat=103&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=u6APR2mGCx4Q7kNvwEN6Ejk&_nc_oc=AdnO1i9MjtrLh4j0pIsezialQS20U8JVn9hE4ZwpUUvIw-2-IzH95kbP5dXHY4gtHTw&_nc_zt=14&_nc_ht=scontent-fra3-1.xx&_nc_gid=qpD_NMiZu30NBzE2MUus2w&oh=00_AfbXQXFFQ_zdSLpcnXZ4aVewkE0koGRDUrX3z27iHe-YZA&oe=68C49D30)

[A critical review of large language models: Sensitivity, bias, and the path toward specialized AI](https://direct.mit.edu/qss/article/5/3/736/120940/A-critical-review-of-large-language-models)

[Measuring General Intelligence with Generated Games](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-60.pdf)

[Maia-2: A Unified Model for Human-AI Alignment in Chess](https://www.cs.toronto.edu/~ashton/pubs/maia2-neurips2024.pdf)

[Judge AI: Assessing Large Language Models in Judicial Decision- Judge AI: Assessing Large Language Models in Judicial Decision-Making](https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=2714&context=law_and_economics)

[Aligning Superhuman AI with Human Behavior: Chess as a Model System](https://www.cs.toronto.edu/~ashton/pubs/maia-kdd2020.pdf)

[OK, I can partly explain the LLM chess weirdness now](https://dynomight.net/more-chess/)

[ChessGPT: Bridging Policy Learning and Language Modeling](https://arxiv.org/pdf/2306.09200)
